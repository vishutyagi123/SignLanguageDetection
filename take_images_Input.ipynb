{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc451e35-6432-43c9-830f-23b1d9efd953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fbbef-56fb-4028-bdbf-95dc3fc2b098",
   "metadata": {},
   "source": [
    "### Initializing camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8d461-d57a-4b6a-96d3-eaa973d76f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "#     cv2.imwrite('captured_image.jpg', frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4c2ad-6fab-4296-af48-a743773bca2c",
   "metadata": {},
   "source": [
    "### Taking images as input using webcam by creating a folder named as input_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b5824-059d-4ca0-9a88-a52f3aa2e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 0\n",
    "upper = 125\n",
    "alpha = 65\n",
    "digit = 0\n",
    "l = [0,125,124,248,246,369,367,491,490,611]\n",
    "prev = 0\n",
    "curr = 1\n",
    "count = 0\n",
    "flag = False\n",
    "\n",
    "!mkdir {'input_images'}\n",
    "while upper <= 982:\n",
    "  img_name = img[lower:upper, l[prev]:l[curr]]\n",
    "  if count < 3:\n",
    "    if alpha == 69:\n",
    "#         cv2.imwrite(f'input_images\\\\Delete.jpg' ,img_name)\n",
    "        cv2.imshow(\"window\",img_name)\n",
    "        count = count + 1\n",
    "        alpha = alpha + 1\n",
    "        prev = (curr + 1) % len(l)\n",
    "        curr = (prev + 1) % len(l)\n",
    "        if curr == 1:\n",
    "           lower = upper\n",
    "           upper = upper + 122\n",
    "        continue\n",
    "        \n",
    "    elif alpha == 79:\n",
    "#         cv2.imwrite(f'input_images\\\\Nothing.jpg' ,img_name)  \n",
    "        cv2.imshow(\"window\",img_name)\n",
    "        count = count + 1\n",
    "        alpha = alpha + 1\n",
    "        prev = (curr + 1) % len(l)\n",
    "        curr = (prev + 1) % len(l)\n",
    "        continue\n",
    "    \n",
    "    elif alpha == 84:\n",
    "#         cv2.imwrite(f'input_images\\\\Space.jpg' ,img_name) \n",
    "        cv2.imshow(\"window\",img_name)\n",
    "        count = count + 1\n",
    "        alpha = alpha + 1\n",
    "        prev = (curr + 1) % len(l)\n",
    "        curr = (prev + 1) % len(l)\n",
    "        alpha = alpha - 1\n",
    "        continue\n",
    "        \n",
    "    if flag:\n",
    "        alpha = alpha - 1\n",
    "        flag = False\n",
    "    \n",
    "  if alpha in (68, 78, 83):\n",
    "    flag = True\n",
    "    \n",
    "  if alpha < 91:\n",
    "#     cv2.imwrite(f'input_images\\\\{chr(alpha)}.jpg' ,img_name)\n",
    "    cv2.imshow(\"window\",img_name)\n",
    "    alpha = alpha + 1\n",
    "  elif alpha >= 91:\n",
    "#     cv2.imwrite(f'input_images\\\\{digit}.jpg' ,img_name)\n",
    "    cv2.imshow(\"window\", img_name)\n",
    "    digit = (digit+1) % len(l)\n",
    "  prev = (curr + 1) % len(l)\n",
    "  curr = (prev + 1) % len(l)\n",
    "\n",
    "  if curr == 1:\n",
    "    lower = upper\n",
    "    upper = upper + 122\n",
    "  cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f008d8e-2dad-4042-8219-2b904eee360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de65e8-b8d3-479c-8a4b-e94670440e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow(\"window\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58544b3e-affd-4b07-97c1-a28f1293a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944cc7e9-7809-4612-9d5e-b4d46ae1a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e1c17-c8c7-4996-9f59-cc2d507e30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "#     mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdfdf32-35a2-4d4f-8549-fab83ea17d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "cwd = Path.cwd()\n",
    "folders = cwd.iterdir()\n",
    "\n",
    "for folder in folders:\n",
    "    files = folder.glob('*')\n",
    "    for file in files:\n",
    "        data_aux = []\n",
    "        img = cv2.imread(str(file))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        results = mp_hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "                    \n",
    "            data.append(data_aux)\n",
    "            labels.append(int(folder.name))\n",
    "        \n",
    "%cd\n",
    "%cd My_work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55645790-84e6-4124-a09e-16ee49288692",
   "metadata": {},
   "source": [
    "- Looking at all the images whether mediapipe is able to recognize all the movements or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
