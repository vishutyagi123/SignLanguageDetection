# Sign Language Detection and Translation
This project aims to develop a robust machine learning model capable of detecting sign language gestures and translating them into English text. By leveraging advanced computer vision techniques and deep learning algorithms, this project seeks to bridge the communication gap for individuals who rely on sign language.

## Demo
https://github.com/user-attachments/assets/a4b69ea5-9c8f-45d4-a942-d68b8c62a807

## Project Overview
### Objective
The primary goal of this project is to create an end-to-end system that:

- Captures sign language gestures through video or images.
- Processes and interprets these gestures using a trained machine learning model.
- Converts the interpreted gestures into coherent English sentences.
#### Key Features
**Real-time Detection:** The system is designed to detect and translate sign language in real-time, providing immediate feedback.
**High Accuracy:** Utilizes state-of-the-art deep learning architectures to ensure high accuracy in gesture recognition.
**User-Friendly Interface:** A simple and intuitive interface for users to interact with the system.
#### Technologies Used
**Machine Learning:** Training a Random Forest Classifier to quickly give the results for live detection using webcam.
**Python:** Core programming language for developing the project.
**TensorFlow/Keras:** Frameworks for building and training the neural network models.
**OpenCV:** Library for real-time computer vision tasks.
**Flask/Django:** Backend framework for deploying the application.
